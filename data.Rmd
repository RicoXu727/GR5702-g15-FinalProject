# Data

## Sources

(Describe the data sources: who is responsible for collecting the data? How is it collected? If there were a choice of options, explain how you chose. (It's ok if there some repetition with the previous chapter. Chapter 2 will reflect your thinking at the time of the proposal and Chapter 3 will represent the state of the project when it is complete.)

Provide some basic information about the data: types of variables, number of records, etc.

Describe any issues / problems with the data, either known or that you discover.)

(suggested: approximately 1 page)

In this [2019 Iowa Liquor Sales dataset](%5Bhttps://data.iowa.gov/Sales-Distribution/2019-Iowa-Liquor-Sales/38x4-vs5h),](<https://data.iowa.gov/Sales-Distribution/2019-Iowa-Liquor-Sales/38x4-vs5h>),) there are very few missing values. There are as many as 24 attributes, which include Date of consumption, Store Name, Category Name, Vendor name and more, detailing every single alcohol consumption. In addition, this dataset is rich in Catigorical Data as well as Numerical Data, and we can use as many kinds of charts as possible to explore the data in the subsequent analysis.

The dataset was collected from grocery stores, liquor stores, convenience stores and so on which has Class E liquor license. We can export it as csv file and import to Rstudio. The dataset consists of 2.38 million points with 24 columns. With reference to the purpose of our study, we do not need to use all of the data.

Basic information about the data:

## Cleaning / transformation

Since the source data file size is too large, the source file is over 500MB, which exceeds the limit of GitHub upload and R manipulation, we first used Python to randomly sample one-tenth of the data as the research data for this project.

```{r}
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(forcats)
```

```{r}
# data <- readr::read_csv("/Users/ricole/Desktop/Leetcode-Note/2019_Iowa_Liquor_Sales_sample.csv", show_col_types = FALSE)
mydata <- readr::read_csv("https://raw.githubusercontent.com/RicoXu727/Leetcode-Note/main/2019_Iowa_Liquor_Sales_sample.csv", show_col_types = FALSE)
```

Second, we eliminated some redundant column data according to the need of the study.

```{r}
drop <- c("Invoice/Item Number","Address", "Store Location", "Volume Sold (Liters)")
subdata = mydata[,!(names(mydata) %in% drop)]
```

## Missing value analysis

To explore the presence of missing values, we first count how many missing values exist for each column. From the displayed results, we have a small percentage of missing values in our dataset, for example Store Name, Store Number, Date and these columns do not have missing values. The attributes that do have the highest number of values are concentrated in City, Zip Code, County Number, County. And they have the same exact data, which inspired us to explore the pattern of missing values.

```{r}
colSums(is.na(subdata)) %>%
  sort(decreasing = TRUE)
```

```{r, width = 800, height = 500}
library(naniar)
gg_miss_upset(subdata, text.scale = 1)
```

The package naniar provides us with a good visualization method. gg_miss_upset function visually shows us what the missing data values are and which columns have missing values. In addition to that, there are some associated missing values column, connected by a solid black line. There is a clear and strong correlation between the geographical location and the attributes of the city. In City, Zip Code, County Number, County. Once one is missing, all other values are also missing. They are a set of combinations together. In addition, another independent missing value attribute is Category Name, but there are not many, out of 100,000 data, only 115 data do not have this attribute.

Since the absence of a particular attribute in the data is rare, direct deletion does not affect the rendering of the data. We choose to delete the missing value using na.omit() function.

```{r}
newdata <- na.omit(subdata)
```
